{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOPz9vvnfS6P7YjqaZ+Azm/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Witcape/PSO/blob/main/QPSO_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "F-AAMxSDdb9d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import re\n",
        "\n",
        "def find_weight(llm, w_values, g_values):\n",
        "    prompt = f\"Update the weight to minimize the cost function. Consider the last five weights: {w_values[-5:]} and the last five cost values: {g_values[-5:]}. Compute the next weight aiming to minimize the cost function. Respond only with the updated weight in decimal formâ€”no additional text or explanations.\"\n",
        "\n",
        "    w_finder_template = f'''SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\n",
        "\n",
        "USER: {prompt}\n",
        "\n",
        "ASSISTANT:\n",
        "    '''\n",
        "    response = llm(prompt=w_finder_template, max_tokens=256, temperature=0.5, top_p=0.95, repeat_penalty=1.2, top_k=150, echo=True)\n",
        "\n",
        "    # Extract decimal weight from response text\n",
        "    text_response = response['choices'][0]['text']\n",
        "    value = re.findall(r'-?\\d+\\.\\d+', text_response)\n",
        "\n",
        "    # Fallback in case LLM does not return a number\n",
        "    return float(value[-1]) if value else w_values[-1]\n",
        "\n",
        "\n",
        "\n",
        "def initialize_llm(model_name_or_path, model_basename, n_threads=2, n_batch=512, n_gpu_layers=32):\n",
        "    model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n",
        "    lcpp_llm = Llama(\n",
        "        model_path=model_path,\n",
        "        n_threads=n_threads,\n",
        "        n_batch=n_batch,\n",
        "        n_gpu_layers=n_gpu_layers\n",
        "    )# GPU\n",
        "    lcpp_llm = None\n",
        "    lcpp_llm = Llama(\n",
        "        model_path=model_path,\n",
        "        n_threads=2, # CPU cores\n",
        "        n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
        "        n_gpu_layers=32 # Change this value based on your model and your GPU VRAM pool.\n",
        "        )\n",
        "    return lcpp_llm\n",
        "\n",
        "class Particle(object):\n",
        "    def __init__(self, bounds):\n",
        "        self._x = np.zeros(len(bounds))\n",
        "        for idx, (lo, hi) in enumerate(bounds):\n",
        "            self._x[idx] = random.uniform(lo, hi)\n",
        "        self._best = self._x.copy()\n",
        "        self._best_value = np.NaN\n",
        "\n",
        "    @property\n",
        "    def best(self):\n",
        "        return self._best\n",
        "\n",
        "    def set_best(self, x):\n",
        "        self._best[:] = x\n",
        "\n",
        "    @property\n",
        "    def best_value(self):\n",
        "        return self._best_value\n",
        "\n",
        "    def set_best_value(self, v):\n",
        "        self._best_value = v\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        return self._x[key]\n",
        "\n",
        "    def __setitem__(self, key, val):\n",
        "        self._x[key] = val\n",
        "\n",
        "\n",
        "class Swarm(object):\n",
        "    def __init__(self, size, dim, bounds):\n",
        "        self._particles = [Particle(bounds) for _ in range(size)]\n",
        "        self._dim = dim\n",
        "        self._gbest_value = None\n",
        "        self._gbest = None\n",
        "\n",
        "    def size(self):\n",
        "        return len(self._particles)\n",
        "\n",
        "    def particles(self):\n",
        "        return self._particles\n",
        "\n",
        "    def mean_best(self):\n",
        "        x = np.zeros(self._dim)\n",
        "        for p in self._particles:\n",
        "            x += p.best\n",
        "        return x / self.size()\n",
        "\n",
        "    @property\n",
        "    def gbest(self):\n",
        "        return self._gbest\n",
        "\n",
        "    @property\n",
        "    def gbest_value(self):\n",
        "        return self._gbest_value\n",
        "\n",
        "    def update_gbest(self):\n",
        "        pg = min(self._particles, key=lambda p: p.best_value)\n",
        "        if self._gbest_value is None or self._gbest_value > pg.best_value:\n",
        "            self._gbest = pg.best.copy()\n",
        "            self._gbest_value = pg.best_value\n",
        "\n",
        "\n",
        "class QPSO(Swarm):\n",
        "    def __init__(self, cf, size, dim, bounds, maxIters, llm):\n",
        "        super(QPSO, self).__init__(size, dim, bounds)\n",
        "        self._cf = cf\n",
        "        self._maxIters = maxIters\n",
        "        self._iters = 0\n",
        "        self.llm = llm  # LLM initialized here\n",
        "        self.init_eval()\n",
        "\n",
        "    def llm_cost_function(self, particle_position):\n",
        "    input_text = f\"Evaluate cost for position: {particle_position}\"\n",
        "    response = self.llm(input_text)\n",
        "\n",
        "    # Print the raw response for debugging\n",
        "    print(\"LLM Response:\", response)  # Debugging: print the raw response\n",
        "\n",
        "    # Assuming response is a dictionary with a 'choices' key\n",
        "    text_response = response['choices'][0]['text']  # Extract the text response\n",
        "    value = re.findall(r'-?\\d+\\.\\d+', text_response)  # Use regex to find floating-point numbers\n",
        "\n",
        "    if value:\n",
        "        return float(value[-1])  # Return the last found float value\n",
        "    else:\n",
        "        raise ValueError(\"No valid cost value found in the LLM response.\")\n",
        "\n",
        "\n",
        "\n",
        "    def init_eval(self):\n",
        "        for p in self._particles:\n",
        "            cost_value = self.llm_cost_function(p[:])\n",
        "            p.set_best_value(cost_value)\n",
        "        self.update_gbest()\n",
        "\n",
        "    def update_best(self):\n",
        "        for p in self._particles:\n",
        "            cost_value = self.llm_cost_function(p[:])\n",
        "            if cost_value < p.best_value:\n",
        "                p.set_best(p[:])\n",
        "                p.set_best_value(cost_value)\n",
        "        self.update_gbest()\n",
        "\n",
        "    def kernel_update(self, **kwargs):\n",
        "        pass  # Placeholder for the QPSO-specific kernel update logic\n",
        "\n",
        "    def update(self, callback=None, interval=None):\n",
        "        while self._iters <= self._maxIters:\n",
        "            self.kernel_update()\n",
        "            self.update_best()\n",
        "            if callback and (self._iters % interval == 0):\n",
        "                callback(self)\n",
        "            self._iters += 1\n",
        "\n",
        "    @property\n",
        "    def iters(self):\n",
        "        return self._iters\n",
        "\n",
        "    @property\n",
        "    def maxIters(self):\n",
        "        return self._maxIters\n",
        "\n",
        "\n",
        "\n",
        "class QDPSO(QPSO):\n",
        "    def __init__(self, cf, size, dim, bounds, maxIters, g, llm):\n",
        "        super(QDPSO, self).__init__(cf, size, dim, bounds, maxIters, llm)\n",
        "        self._g = g\n",
        "        self._weights = [0.5]  # Starting weight for demonstration\n",
        "        self._costs = []\n",
        "\n",
        "    def kernel_update(self, **kwargs):\n",
        "        # Adjust weight using LLM-guided find_weight function if enough cost history is available\n",
        "        if len(self._costs) >= 5:\n",
        "            new_weight = find_weight(self.llm, self._weights, self._costs)\n",
        "            self._weights.append(new_weight)\n",
        "        else:\n",
        "            new_weight = self._weights[-1]\n",
        "\n",
        "        # Print the current weight for monitoring\n",
        "        print(f\"Iteration {self._iters + 1}: Current weight = {new_weight:.4f}\")\n",
        "\n",
        "        # Particle update logic using the new weight\n",
        "        for p in self._particles:\n",
        "            for i in range(self._dim):\n",
        "                u1, u2, u3 = random.uniform(0., 1.), random.uniform(0., 1.), random.uniform(0., 1.)\n",
        "                rand_sign = 1 if random.random() > 0.5 else -1\n",
        "                c = (u1 * p.best[i] + u2 * self._gbest[i]) / (u1 + u2)\n",
        "                L = (1 / self._g) * abs(p[i] - c)\n",
        "                p[i] = c + rand_sign * L * np.log(1. / u3)\n",
        "\n",
        "        # Record the current best cost for reference in weight adjustment\n",
        "        self._costs.append(self.gbest_value)\n",
        "        print(f\"Best solution cost at Iteration {self._iters + 1}: {self.gbest_value:.4f}\\n\")\n",
        "\n",
        "    def update(self, callback=None, interval=None):\n",
        "        while self._iters <= self._maxIters:\n",
        "            print(f\"\\nStarting Iteration {self._iters + 1}...\")\n",
        "            self.kernel_update()  # Update particles based on kernel logic\n",
        "            self.update_best()  # Re-evaluate particle bests and global best\n",
        "            if callback and (self._iters % interval == 0):\n",
        "                callback(self)\n",
        "            self._iters += 1\n",
        "\n",
        "\n",
        "\n",
        "def run_qdpso(cf, size, dim, bounds, maxIters, g, llm, callback=None, interval=None):\n",
        "    \"\"\"\n",
        "    Run the QDPSO algorithm.\n",
        "\n",
        "    :param cf: Cost function (ignored in this implementation, using LLM for cost).\n",
        "    :param size: Number of particles in the swarm.\n",
        "    :param dim: Dimensionality of the problem space.\n",
        "    :param bounds: Bounds for each dimension (list of (low, high) tuples).\n",
        "    :param maxIters: Maximum number of iterations.\n",
        "    :param g: Quantum parameter for QDPSO.\n",
        "    :param llm: Large language model function that provides cost evaluations.\n",
        "    :param callback: Optional callback function for custom monitoring.\n",
        "    :param interval: Interval for callback invocation.\n",
        "    :return: Best solution and its cost found by QDPSO.\n",
        "    \"\"\"\n",
        "    qdpso = QDPSO(cf, size, dim, bounds, maxIters, g, llm)\n",
        "    qdpso.update(callback=callback, interval=interval)\n",
        "    return qdpso.gbest, qdpso.gbest_value"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OTJUgktUdfEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uo24d6fmdfMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LzEi0KprdfPt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}