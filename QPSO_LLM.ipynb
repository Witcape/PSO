{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPvyKPeAVwlCw0R5toqDYsP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Witcape/PSO/blob/main/QPSO_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-AAMxSDdb9d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama\n",
        "from typing import List, Tuple\n",
        "\n",
        "# Define the Sphere Function\n",
        "def sphere_function(x: np.ndarray) -> float:\n",
        "    \"\"\"Sphere function: f(x) = sum(x_i^2)\"\"\"\n",
        "    return np.sum(x ** 2)\n",
        "\n",
        "# Initialize the LLM\n",
        "def initialize_llm(model_name_or_path: str, model_basename: str, n_threads: int = 2,\n",
        "                  n_batch: int = 512, n_gpu_layers: int = 32) -> Llama:\n",
        "    \"\"\"\n",
        "    Initialize the LLM using llama_cpp.\n",
        "\n",
        "    :param model_name_or_path: Repository ID on Hugging Face Hub.\n",
        "    :param model_basename: Model filename.\n",
        "    :param n_threads: Number of CPU threads.\n",
        "    :param n_batch: Batch size.\n",
        "    :param n_gpu_layers: Number of GPU layers to offload.\n",
        "    :return: Initialized Llama model.\n",
        "    \"\"\"\n",
        "    model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n",
        "    lcpp_llm = Llama(\n",
        "        model_path=model_path,\n",
        "        n_threads=n_threads,\n",
        "        n_batch=n_batch,\n",
        "        n_gpu_layers=n_gpu_layers\n",
        "    )\n",
        "    return lcpp_llm\n",
        "\n",
        "# Function to Find New Weight Using LLM\n",
        "def find_weight(llm: Llama, w_values: List[float], g_values: List[float]) -> float:\n",
        "    \"\"\"\n",
        "    Use the LLM to suggest a new weight based on recent weights and cost values.\n",
        "\n",
        "    :param llm: Initialized Llama model.\n",
        "    :param w_values: List of recent weight values.\n",
        "    :param g_values: List of recent cost values.\n",
        "    :return: Suggested new weight.\n",
        "    \"\"\"\n",
        "    prompt = (f\"Update the weight to minimize the cost function. Consider the last five weights: {w_values[-5:]} \"\n",
        "              f\"and the last five cost values: {g_values[-5:]}. Compute the next weight aiming to minimize \"\n",
        "              f\"the cost function. Respond only with the updated weight in decimal formâ€”no additional text or explanations.\")\n",
        "\n",
        "    w_finder_template = f'''SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\n",
        "\n",
        "USER: {prompt}\n",
        "\n",
        "ASSISTANT:\n",
        "    '''\n",
        "    response = llm(prompt=w_finder_template, max_tokens=256, temperature=0.5, top_p=0.95,\n",
        "                  repeat_penalty=1.2, top_k=150, echo=True)\n",
        "\n",
        "    # Extract decimal weight from response text\n",
        "    text_response = response['choices'][0]['text']\n",
        "    value = re.findall(r'-?\\d+\\.\\d+', text_response)\n",
        "\n",
        "    # Fallback in case LLM does not return a number\n",
        "    new_weight = float(value[-1]) if value else w_values[-1]\n",
        "    print(f\"[DEBUG] New weight from LLM: {new_weight}\")\n",
        "    return new_weight\n",
        "\n",
        "# Define Particle Class\n",
        "class Particle:\n",
        "    def __init__(self, bounds: List[Tuple[float, float]]):\n",
        "        self._x = np.zeros(len(bounds))\n",
        "        for idx, (lo, hi) in enumerate(bounds):\n",
        "            self._x[idx] = random.uniform(lo, hi)\n",
        "        self._best = self._x.copy()\n",
        "        self._best_value = np.NaN\n",
        "\n",
        "    @property\n",
        "    def best(self) -> np.ndarray:\n",
        "        return self._best\n",
        "\n",
        "    def set_best(self, x: np.ndarray):\n",
        "        self._best[:] = x\n",
        "\n",
        "    @property\n",
        "    def best_value(self) -> float:\n",
        "        return self._best_value\n",
        "\n",
        "    def set_best_value(self, v: float):\n",
        "        self._best_value = v\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        return self._x[key]\n",
        "\n",
        "    def __setitem__(self, key, val):\n",
        "        self._x[key] = val\n",
        "\n",
        "# Define Swarm Class\n",
        "class Swarm:\n",
        "    def __init__(self, size: int, dim: int, bounds: List[Tuple[float, float]]):\n",
        "        self._particles = [Particle(bounds) for _ in range(size)]\n",
        "        self._dim = dim\n",
        "        self._gbest_value = None\n",
        "        self._gbest = None\n",
        "\n",
        "    def size(self) -> int:\n",
        "        return len(self._particles)\n",
        "\n",
        "    def particles(self) -> List[Particle]:\n",
        "        return self._particles\n",
        "\n",
        "    def mean_best(self) -> np.ndarray:\n",
        "        x = np.zeros(self._dim)\n",
        "        for p in self._particles:\n",
        "            x += p.best\n",
        "        return x / self.size()\n",
        "\n",
        "    @property\n",
        "    def gbest(self) -> np.ndarray:\n",
        "        return self._gbest\n",
        "\n",
        "    @property\n",
        "    def gbest_value(self) -> float:\n",
        "        return self._gbest_value\n",
        "\n",
        "    def update_gbest(self):\n",
        "        pg = min(self._particles, key=lambda p: p.best_value)\n",
        "        if self._gbest_value is None or pg.best_value < self._gbest_value:\n",
        "            self._gbest = pg.best.copy()\n",
        "            self._gbest_value = pg.best_value\n",
        "\n",
        "# Define QPSO Class\n",
        "class QPSO(Swarm):\n",
        "    def __init__(self, cf, size: int, dim: int, bounds: List[Tuple[float, float]],\n",
        "                 maxIters: int, llm: Llama):\n",
        "        super(QPSO, self).__init__(size, dim, bounds)\n",
        "        self._cf = cf  # Cost function\n",
        "        self._maxIters = maxIters\n",
        "        self._iters = 0\n",
        "        self.llm = llm  # LLM for cost evaluations\n",
        "        self.init_eval()\n",
        "\n",
        "    def llm_cost_function(self, particle_position: np.ndarray) -> float:\n",
        "        input_text = f\"Evaluate cost for position: {particle_position.tolist()}\"\n",
        "        print(\"[DEBUG] Input to LLM:\", input_text)  # Debugging: print the input text\n",
        "\n",
        "        response = self.llm(prompt=input_text, max_tokens=256, temperature=0.5, top_p=0.95,\n",
        "                           repeat_penalty=1.2, top_k=150, echo=True)  # Call the LLM\n",
        "\n",
        "        # Print the raw response for debugging\n",
        "        print(\"[DEBUG] LLM Response:\", response)  # Debugging: print the raw response\n",
        "\n",
        "        # Assuming response is a dictionary with a 'choices' key\n",
        "        if isinstance(response, dict) and 'choices' in response:\n",
        "            text_response = response['choices'][0]['text']  # Extract the text response\n",
        "            value = re.findall(r'-?\\d+\\.\\d+', text_response)  # Use regex to find floating-point numbers\n",
        "\n",
        "            if value:\n",
        "                return float(value[-1])  # Return the last found float value\n",
        "            else:\n",
        "                print(\"[WARNING] No valid cost value found in the LLM response. Using default cost.\")\n",
        "                return self._cf(particle_position)  # Fallback to actual cost function\n",
        "        else:\n",
        "            print(\"[WARNING] LLM response is not in the expected format. Using default cost.\")\n",
        "            return self._cf(particle_position)  # Fallback to actual cost function\n",
        "\n",
        "    def init_eval(self):\n",
        "        for p in self._particles:\n",
        "            cost_value = self.llm_cost_function(p[:])\n",
        "            p.set_best_value(cost_value)\n",
        "        self.update_gbest()\n",
        "\n",
        "    def update_best(self):\n",
        "        for p in self._particles:\n",
        "            cost_value = self.llm_cost_function(p[:])\n",
        "            if np.isnan(p.best_value) or cost_value < p.best_value:\n",
        "                p.set_best(p[:])\n",
        "                p.set_best_value(cost_value)\n",
        "        self.update_gbest()\n",
        "\n",
        "    def kernel_update(self, **kwargs):\n",
        "        pass  # Placeholder for the QPSO-specific kernel update logic\n",
        "\n",
        "    def update(self, callback=None, interval=None):\n",
        "        while self._iters < self._maxIters:\n",
        "            self.kernel_update()\n",
        "            self.update_best()\n",
        "            if callback and (self._iters % interval == 0):\n",
        "                callback(self)\n",
        "            self._iters += 1\n",
        "\n",
        "    @property\n",
        "    def iters(self) -> int:\n",
        "        return self._iters\n",
        "\n",
        "    @property\n",
        "    def maxIters(self) -> int:\n",
        "        return self._maxIters\n",
        "\n",
        "# Define QDPSO Class\n",
        "class QDPSO(QPSO):\n",
        "    def __init__(self, cf, size: int, dim: int, bounds: List[Tuple[float, float]],\n",
        "                 maxIters: int, g: float, llm: Llama):\n",
        "        super(QDPSO, self).__init__(cf, size, dim, bounds, maxIters, llm)\n",
        "        self._g = g  # Quantum parameter\n",
        "        self._weights = [0.5]  # Starting weight for demonstration\n",
        "        self._costs = []\n",
        "\n",
        "    def kernel_update(self, **kwargs):\n",
        "        # Adjust weight using LLM-guided find_weight function if enough cost history is available\n",
        "        if len(self._costs) >= 5 and len(self._weights) >= 5:\n",
        "            new_weight = find_weight(self.llm, self._weights, self._costs)\n",
        "            self._weights.append(new_weight)\n",
        "        elif len(self._weights) < 5:\n",
        "            new_weight = self._weights[-1]\n",
        "        else:\n",
        "            new_weight = self._weights[-1]\n",
        "\n",
        "        # Print the current weight for monitoring\n",
        "        print(f\"[DEBUG] Iteration {self._iters + 1}: Current weight = {new_weight:.4f}\")\n",
        "\n",
        "        # Particle update logic using the new weight\n",
        "        for p in self._particles:\n",
        "            for i in range(self._dim):\n",
        "                u1 = random.uniform(0., 1.)\n",
        "                u2 = random.uniform(0., 1.)\n",
        "                u3 = random.uniform(0., 1.)\n",
        "                rand_sign = 1 if random.random() > 0.5 else -1\n",
        "                c = (u1 * p.best[i] + u2 * self.gbest[i]) / (u1 + u2)\n",
        "                L = (1 / self._g) * abs(p[i] - c)\n",
        "                p[i] = c + rand_sign * L * np.log(1. / u3)\n",
        "\n",
        "        # Record the current best cost for reference in weight adjustment\n",
        "        self._costs.append(self.gbest_value)\n",
        "        print(f\"[INFO] Best solution cost at Iteration {self._iters + 1}: {self.gbest_value:.4f}\\n\")\n",
        "\n",
        "    def update_best(self):\n",
        "        for p in self._particles:\n",
        "            cost_value = self.llm_cost_function(p[:])\n",
        "            if np.isnan(p.best_value) or cost_value < p.best_value:\n",
        "                p.set_best(p[:])\n",
        "                p.set_best_value(cost_value)\n",
        "        self.update_gbest()\n",
        "\n",
        "    def update(self, callback=None, interval=None):\n",
        "        while self._iters < self._maxIters:\n",
        "            print(f\"\\n[INFO] Starting Iteration {self._iters + 1}...\")\n",
        "            self.kernel_update()  # Update particles based on kernel logic\n",
        "            self.update_best()  # Re-evaluate particle bests and global best\n",
        "            if callback and (self._iters % interval == 0):\n",
        "                callback(self)\n",
        "            self._iters += 1\n",
        "\n",
        "# Function to Run QDPSO\n",
        "def run_qdpso(cf, size: int, dim: int, bounds: List[Tuple[float, float]],\n",
        "             maxIters: int, g: float, llm: Llama,\n",
        "             callback=None, interval: int = 10):\n",
        "    \"\"\"\n",
        "    Run the QDPSO algorithm.\n",
        "\n",
        "    :param cf: Cost function.\n",
        "    :param size: Number of particles in the swarm.\n",
        "    :param dim: Dimensionality of the problem space.\n",
        "    :param bounds: Bounds for each dimension (list of (low, high) tuples).\n",
        "    :param maxIters: Maximum number of iterations.\n",
        "    :param g: Quantum parameter for QDPSO.\n",
        "    :param llm: Initialized LLM for weight adjustments.\n",
        "    :param callback: Optional callback function for custom monitoring.\n",
        "    :param interval: Interval for callback invocation.\n",
        "    :return: Best solution and its cost found by QDPSO, along with weight and cost histories.\n",
        "    \"\"\"\n",
        "    qdpso = QDPSO(cf, size, dim, bounds, maxIters, g, llm)\n",
        "    qdpso.update(callback=callback, interval=interval)\n",
        "    return qdpso.gbest, qdpso.gbest_value, qdpso._weights, qdpso._costs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# from scipy.io import loadmat\n",
        "# import matplotlib.pyplot as plt\n",
        "# from huggingface_hub import hf_hub_download\n",
        "# from llama_cpp import Llama\n",
        "# import numpy as np\n",
        "# import re\n",
        "# import matplotlib.pyplot as plt\n",
        "# from pypop7.optimizers.core.optimizer import Optimizer\n",
        "# from pypop7.optimizers.pso.pso import PSO\n",
        "# from scipy.optimize import differential_evolution"
      ],
      "metadata": {
        "id": "pSWgVKSSiy_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.78 numpy==1.23.4 --force-reinstall --upgrade --no-cache-dir --verbose\n",
        "# !pip install huggingface_hub\n",
        "# !pip install llama-cpp-python==0.1.78\n",
        "# !pip install numpy==1.23.4\n",
        "\n",
        "# model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGML\"\n",
        "# model_basename = \"llama-2-13b-chat.ggmlv3.q5_1.bin\""
      ],
      "metadata": {
        "id": "LCF7RbtxivCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGML\"  # Replace with your model repo\n",
        "# model_basename = \"llama-2-13b-chat.ggmlv3.q5_1.bin\"    # Replace with your model filename\n",
        "# llm = initialize_llm(model_name_or_path, model_basename, n_threads=2, n_batch=512, n_gpu_layers=32)"
      ],
      "metadata": {
        "id": "OTJUgktUdfEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# size = 20  # Number of particles\n",
        "# dim = 2    # Dimensions of the problem\n",
        "# bounds = [(-5.0, 5.0) for _ in range(dim)]  # Bounds for each dimension\n",
        "# maxIters = 20  # Maximum number of iterations\n",
        "# g = 1.0         # Quantum parameter"
      ],
      "metadata": {
        "id": "uo24d6fmdfMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best_solution, best_cost, weight_history, cost_history = run_qdpso(\n",
        "#         cf=sphere_function,\n",
        "#         size=size,\n",
        "#         dim=dim,\n",
        "#         bounds=bounds,\n",
        "#         maxIters=maxIters,\n",
        "#         g=g,\n",
        "#         llm=llm,\n",
        "#         callback=None,\n",
        "#         interval=10\n",
        "#     )\n",
        "\n",
        "# print(f\"Best Solution: {best_solution}, Best Cost: {best_cost}\")"
      ],
      "metadata": {
        "id": "LzEi0KprdfPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure(figsize=(12, 5))\n",
        "\n",
        "#     # Plotting Cost History\n",
        "#     plt.subplot(1, 2, 1)\n",
        "#     plt.plot(cost_history, label=\"Cost\", color='blue')\n",
        "#     plt.title(\"Cost History\")\n",
        "#     plt.xlabel(\"Iterations\")\n",
        "#     plt.ylabel(\"Cost\")\n",
        "#     plt.legend()\n",
        "\n",
        "#     # Plotting Weight History\n",
        "#     plt.subplot(1, 2, 2)\n",
        "#     plt.plot(weight_history, label=\"Weight (Quantum Parameter)\", color='orange')\n",
        "#     plt.title(\"Weight History\")\n",
        "#     plt.xlabel(\"Iterations\")\n",
        "#     plt.ylabel(\"Weight\")\n",
        "#     plt.legend()\n",
        "\n",
        "#     # Show the plots\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()"
      ],
      "metadata": {
        "id": "CW8Wni1higcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-SXbQmN0igfT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}