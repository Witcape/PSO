{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "oERE5I7bNyRZ",
        "UREs2TNnZdCq",
        "M4Mu7IQcZdCz",
        "rEOl4LpQZdC0"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "55f6728db4dc46f4bc5c3eb727883cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb623af6f6dd4a66b5cd6827296d434a",
              "IPY_MODEL_bce1bb9d8fa342839ac558ab1a07169b",
              "IPY_MODEL_c46e582fe49c4e41b5c2f41b3813125e"
            ],
            "layout": "IPY_MODEL_0f5e57bfa5bc4bbbab670312bfd6bf86"
          }
        },
        "eb623af6f6dd4a66b5cd6827296d434a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da38155496af4e33a3d5c670958da611",
            "placeholder": "​",
            "style": "IPY_MODEL_ee1c30cd263c4e329477b804bb0939f9",
            "value": "llama-2-13b-chat.ggmlv3.q5_1.bin: 100%"
          }
        },
        "bce1bb9d8fa342839ac558ab1a07169b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68b6b87cdf7248f8952614fbc7a0d716",
            "max": 9763701888,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d49b186044a4fc58f36a6b0fab2b9ed",
            "value": 9763701888
          }
        },
        "c46e582fe49c4e41b5c2f41b3813125e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d4850ada45943a4af77abb4f548baca",
            "placeholder": "​",
            "style": "IPY_MODEL_3a4f8c8a15ea42d8aab854be156d6eb4",
            "value": " 9.76G/9.76G [00:59&lt;00:00, 211MB/s]"
          }
        },
        "0f5e57bfa5bc4bbbab670312bfd6bf86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da38155496af4e33a3d5c670958da611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1c30cd263c4e329477b804bb0939f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68b6b87cdf7248f8952614fbc7a0d716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d49b186044a4fc58f36a6b0fab2b9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d4850ada45943a4af77abb4f548baca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a4f8c8a15ea42d8aab854be156d6eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Witcape/PSO/blob/main/Initialisation_%26_weight_%26_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Installing LLM"
      ],
      "metadata": {
        "id": "9uP6rkKmNnMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install accelerate\n",
        "# import accelerate"
      ],
      "metadata": {
        "id": "kY6BJbl4e8Fb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI3J3o7JdXmC",
        "outputId": "962f8215-d47c-4590-a2e7-639da9b5a46e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Collecting llama-cpp-python==0.1.78\n",
            "  Downloading llama_cpp_python-0.1.78.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Running command pip subprocess to install build dependencies\n",
            "  Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "  Collecting setuptools>=42\n",
            "    Using cached setuptools-70.3.0-py3-none-any.whl (931 kB)\n",
            "  Collecting scikit-build>=0.13\n",
            "    Downloading scikit_build-0.18.0-py3-none-any.whl (85 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.3/85.3 kB 2.2 MB/s eta 0:00:00\n",
            "  Collecting cmake>=3.18\n",
            "    Downloading cmake-3.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.9 MB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.9/26.9 MB 20.6 MB/s eta 0:00:00\n",
            "  Collecting ninja\n",
            "    Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.2/307.2 kB 9.5 MB/s eta 0:00:00\n",
            "  Collecting distro (from scikit-build>=0.13)\n",
            "    Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "  Collecting packaging (from scikit-build>=0.13)\n",
            "    Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.0/54.0 kB 2.9 MB/s eta 0:00:00\n",
            "  Collecting tomli (from scikit-build>=0.13)\n",
            "    Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
            "  Collecting wheel>=0.32.0 (from scikit-build>=0.13)\n",
            "    Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
            "  Installing collected packages: ninja, wheel, tomli, setuptools, packaging, distro, cmake, scikit-build\n",
            "    Creating /tmp/pip-build-env-mob895j1/overlay/local/bin\n",
            "    changing mode of /tmp/pip-build-env-mob895j1/overlay/local/bin/ninja to 755\n",
            "    changing mode of /tmp/pip-build-env-mob895j1/overlay/local/bin/wheel to 755\n",
            "    changing mode of /tmp/pip-build-env-mob895j1/overlay/local/bin/distro to 755\n",
            "    changing mode of /tmp/pip-build-env-mob895j1/overlay/local/bin/cmake to 755\n",
            "    changing mode of /tmp/pip-build-env-mob895j1/overlay/local/bin/cpack to 755\n",
            "    changing mode of /tmp/pip-build-env-mob895j1/overlay/local/bin/ctest to 755\n",
            "  ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "  ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "  Successfully installed cmake-3.30.0 distro-1.9.0 ninja-1.11.1.1 packaging-24.1 scikit-build-0.18.0 setuptools-70.3.0 tomli-2.0.1 wheel-0.43.0\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command Getting requirements to build wheel\n",
            "  running egg_info\n",
            "  writing llama_cpp_python.egg-info/PKG-INFO\n",
            "  writing dependency_links to llama_cpp_python.egg-info/dependency_links.txt\n",
            "  writing requirements to llama_cpp_python.egg-info/requires.txt\n",
            "  writing top-level names to llama_cpp_python.egg-info/top_level.txt\n",
            "  reading manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE.md'\n",
            "  writing manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command Preparing metadata (pyproject.toml)\n",
            "  running dist_info\n",
            "  creating /tmp/pip-modern-metadata-dhsxxk4b/llama_cpp_python.egg-info\n",
            "  writing /tmp/pip-modern-metadata-dhsxxk4b/llama_cpp_python.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-modern-metadata-dhsxxk4b/llama_cpp_python.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-modern-metadata-dhsxxk4b/llama_cpp_python.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-modern-metadata-dhsxxk4b/llama_cpp_python.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-modern-metadata-dhsxxk4b/llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-modern-metadata-dhsxxk4b/llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE.md'\n",
            "  writing manifest file '/tmp/pip-modern-metadata-dhsxxk4b/llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  creating '/tmp/pip-modern-metadata-dhsxxk4b/llama_cpp_python-0.1.78.dist-info'\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.23.4\n",
            "  Downloading numpy-1.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.5.0 (from llama-cpp-python==0.1.78)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.1.78)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m228.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Running command Building wheel for llama-cpp-python (pyproject.toml)\n",
            "\n",
            "\n",
            "  --------------------------------------------------------------------------------\n",
            "  -- Trying 'Ninja' generator\n",
            "  --------------------------------\n",
            "  ---------------------------\n",
            "  ----------------------\n",
            "  -----------------\n",
            "  ------------\n",
            "  -------\n",
            "  --\n",
            "  Not searching for unused variables given on the command line.\n",
            "  -- The C compiler identification is GNU 11.4.0\n",
            "  -- Detecting C compiler ABI info\n",
            "  -- Detecting C compiler ABI info - done\n",
            "  -- Check for working C compiler: /usr/bin/cc - skipped\n",
            "  -- Detecting C compile features\n",
            "  -- Detecting C compile features - done\n",
            "  -- The CXX compiler identification is GNU 11.4.0\n",
            "  -- Detecting CXX compiler ABI info\n",
            "  -- Detecting CXX compiler ABI info - done\n",
            "  -- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "  -- Detecting CXX compile features\n",
            "  -- Detecting CXX compile features - done\n",
            "  -- Configuring done (0.7s)\n",
            "  -- Generating done (0.0s)\n",
            "  -- Build files have been written to: /tmp/pip-install-d1pap8o1/llama-cpp-python_2965a974b8f141c1bd64868d2c82f6be/_cmake_test_compile/build\n",
            "  --\n",
            "  -------\n",
            "  ------------\n",
            "  -----------------\n",
            "  ----------------------\n",
            "  ---------------------------\n",
            "  --------------------------------\n",
            "  -- Trying 'Ninja' generator - success\n",
            "  --------------------------------------------------------------------------------\n",
            "\n",
            "  Configuring Project\n",
            "    Working directory:\n",
            "      /tmp/pip-install-d1pap8o1/llama-cpp-python_2965a974b8f141c1bd64868d2c82f6be/_skbuild/linux-x86_64-3.10/cmake-build\n",
            "    Command:\n",
            "      /tmp/pip-build-env-mob895j1/overlay/local/lib/python3.10/dist-packages/cmake/data/bin/cmake /tmp/pip-install-d1pap8o1/llama-cpp-python_2965a974b8f141c1bd64868d2c82f6be -G Ninja -DCMAKE_MAKE_PROGRAM:FILEPATH=/tmp/pip-build-env-mob895j1/overlay/local/lib/python3.10/dist-packages/ninja/data/bin/ninja --no-warn-unused-cli -DCMAKE_INSTALL_PREFIX:PATH=/tmp/pip-install-d1pap8o1/llama-cpp-python_2965a974b8f141c1bd64868d2c82f6be/_skbuild/linux-x86_64-3.10/cmake-install -DPYTHON_VERSION_STRING:STRING=3.10.12 -DSKBUILD:INTERNAL=TRUE -DCMAKE_MODULE_PATH:PATH=/tmp/pip-build-env-mob895j1/overlay/local/lib/python3.10/dist-packages/skbuild/resources/cmake -DPYTHON_EXECUTABLE:PATH=/usr/bin/python3 -DPYTHON_INCLUDE_DIR:PATH=/usr/include/python3.10 -DPYTHON_LIBRARY:PATH=/usr/lib/x86_64-linux-gnu/libpython3.10.so -DPython_EXECUTABLE:PATH=/usr/bin/python3 -DPython_ROOT_DIR:PATH=/usr -DPython_FIND_REGISTRY:STRING=NEVER -DPython_INCLUDE_DIR:PATH=/usr/include/python3.10 -DPython3_EXECUTABLE:PATH=/usr/bin/python3 -DPython3_ROOT_DIR:PATH=/usr -DPython3_FIND_REGISTRY:STRING=NEVER -DPython3_INCLUDE_DIR:PATH=/usr/include/python3.10 -DCMAKE_MAKE_PROGRAM:FILEPATH=/tmp/pip-build-env-mob895j1/overlay/local/lib/python3.10/dist-packages/ninja/data/bin/ninja -DLLAMA_CUBLAS=on -DCMAKE_BUILD_TYPE:STRING=Release -DLLAMA_CUBLAS=on\n",
            "\n",
            "  Not searching for unused variables given on the command line.\n",
            "  -- The C compiler identification is GNU 11.4.0\n",
            "  -- The CXX compiler identification is GNU 11.4.0\n",
            "  -- Detecting C compiler ABI info\n",
            "  -- Detecting C compiler ABI info - done\n",
            "  -- Check for working C compiler: /usr/bin/cc - skipped\n",
            "  -- Detecting C compile features\n",
            "  -- Detecting C compile features - done\n",
            "  -- Detecting CXX compiler ABI info\n",
            "  -- Detecting CXX compiler ABI info - done\n",
            "  -- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "  -- Detecting CXX compile features\n",
            "  -- Detecting CXX compile features - done\n",
            "  -- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "  fatal: not a git repository (or any of the parent directories): .git\n",
            "  fatal: not a git repository (or any of the parent directories): .git\n",
            "  CMake Warning at vendor/llama.cpp/CMakeLists.txt:117 (message):\n",
            "    Git repository not found; to enable automatic generation of build info,\n",
            "    make sure Git is installed and the project is a Git repository.\n",
            "\n",
            "\n",
            "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "  -- Found Threads: TRUE\n",
            "  -- Found CUDAToolkit: /usr/local/cuda/targets/x86_64-linux/include (found version \"12.2.140\")\n",
            "  -- cuBLAS found\n",
            "  -- The CUDA compiler identification is NVIDIA 12.2.140\n",
            "  -- Detecting CUDA compiler ABI info\n",
            "  -- Detecting CUDA compiler ABI info - done\n",
            "  -- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
            "  -- Detecting CUDA compile features\n",
            "  -- Detecting CUDA compile features - done\n",
            "  -- Using CUDA architectures: 52;61;70\n",
            "  -- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "  -- x86 detected\n",
            "  -- Configuring done (4.8s)\n",
            "  -- Generating done (0.0s)\n",
            "  -- Build files have been written to: /tmp/pip-install-d1pap8o1/llama-cpp-python_2965a974b8f141c1bd64868d2c82f6be/_skbuild/linux-x86_64-3.10/cmake-build\n",
            "  [1/9] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o\n",
            "  [2/9] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/k_quants.c.o\n",
            "  [3/9] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o\n",
            "  [4/9] Building CXX object vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o\n",
            "  [5/9] Building CUDA object vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o\n",
            "  [6/9] Linking CXX shared library vendor/llama.cpp/libllama.so\n",
            "  [7/9] Linking CUDA shared library vendor/llama.cpp/libggml_shared.so\n",
            "  [8/9] Linking CUDA static library vendor/llama.cpp/libggml_static.a\n",
            "  [8/9] Install the project...\n",
            "  -- Install configuration: \"Release\"\n",
            "  -- Installing: /tmp/pip-install-d1pap8o1/llama-cpp-python_2965a974b8f141c1bd64868d2c82f6be/_skbuild/linux-x86_64-3.10/cmake-install/lib/libggml_shared.so\n",
            "  -- Installing: /tmp/pip-install-d1pap8o1/llama-cpp-python_2965a974b8f141c1bd64868d2c82f6be/_skbuild/linux-x86_64-3.10/cmake-install/lib/libllama.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/pip-install-d1pap8o1/llama-cpp-python_2965a974b8f141c1bd64868d2c82f6be/_skbuild/linux-x86_64-3.10/cmake-install/lib/libllama.so\" to \"\"\n",
            "  -- Installing: /tmp/pip-install-d1pap8o1/llama-cpp-python_2965a974b8f141c1bd64868d2c82f6be/_skbuild/linux-x86_64-3.10/cmake-install/bin/convert.py\n",
            "  -- Installing: /tmp/pip-install-d1pap8o1/llama-cpp-python_2965a974b8f141c1bd64868d2c82f6be/_skbuild/linux-x86_64-3.10/cmake-install/bin/convert-lora-to-ggml.py\n",
            "  -- Installing: /tmp/pip-install-d1pap8o1/llama-cpp-python_2965a974b8f141c1bd64868d2c82f6be/_skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/libllama.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/pip-install-d1pap8o1/llama-cpp-python_2965a974b8f141c1bd64868d2c82f6be/_skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/libllama.so\" to \"\"\n",
            "\n",
            "  copying llama_cpp/llama_grammar.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_grammar.py\n",
            "  copying llama_cpp/llama_cpp.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_cpp.py\n",
            "  copying llama_cpp/__init__.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/__init__.py\n",
            "  copying llama_cpp/llama.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama.py\n",
            "  copying llama_cpp/llama_types.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_types.py\n",
            "  copying llama_cpp/utils.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/utils.py\n",
            "  creating directory _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server\n",
            "  copying llama_cpp/server/app.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/app.py\n",
            "  copying llama_cpp/server/__main__.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__main__.py\n",
            "  copying llama_cpp/server/__init__.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__init__.py\n",
            "  copying /tmp/pip-install-d1pap8o1/llama-cpp-python_2965a974b8f141c1bd64868d2c82f6be/llama_cpp/py.typed -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/py.typed\n",
            "\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_grammar.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_cpp.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_types.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/utils.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/app.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__main__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/py.typed -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/libllama.so -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_grammar.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_cpp.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_types.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/utils.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/app.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__main__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copied 9 files\n",
            "  running build_ext\n",
            "  installing to _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/llama_grammar.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/llama_cpp.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/py.typed -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/llama.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/libllama.so -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server/app.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server/__main__.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/llama_types.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/utils.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copied 11 files\n",
            "  running install_data\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/lib\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/lib/libllama.so -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/lib\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/lib/libggml_shared.so -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/lib\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/bin\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/bin/convert.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/bin\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/bin/convert-lora-to-ggml.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/bin\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing llama_cpp_python.egg-info/PKG-INFO\n",
            "  writing dependency_links to llama_cpp_python.egg-info/dependency_links.txt\n",
            "  writing requirements to llama_cpp_python.egg-info/requires.txt\n",
            "  writing top-level names to llama_cpp_python.egg-info/top_level.txt\n",
            "  reading manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE.md'\n",
            "  writing manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  Copying llama_cpp_python.egg-info to _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78-py3.10.egg-info\n",
            "  running install_scripts\n",
            "  copied 0 files\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-lymqkix8/.tmp-f2x1u4vk/llama_cpp_python-0.1.78-cp310-cp310-linux_x86_64.whl' and adding '_skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'llama_cpp/__init__.py'\n",
            "  adding 'llama_cpp/libllama.so'\n",
            "  adding 'llama_cpp/llama.py'\n",
            "  adding 'llama_cpp/llama_cpp.py'\n",
            "  adding 'llama_cpp/llama_grammar.py'\n",
            "  adding 'llama_cpp/llama_types.py'\n",
            "  adding 'llama_cpp/py.typed'\n",
            "  adding 'llama_cpp/utils.py'\n",
            "  adding 'llama_cpp/server/__init__.py'\n",
            "  adding 'llama_cpp/server/__main__.py'\n",
            "  adding 'llama_cpp/server/app.py'\n",
            "  adding 'llama_cpp_python-0.1.78.data/data/bin/convert-lora-to-ggml.py'\n",
            "  adding 'llama_cpp_python-0.1.78.data/data/bin/convert.py'\n",
            "  adding 'llama_cpp_python-0.1.78.data/data/lib/libggml_shared.so'\n",
            "  adding 'llama_cpp_python-0.1.78.data/data/lib/libllama.so'\n",
            "  adding 'llama_cpp_python-0.1.78.dist-info/LICENSE.md'\n",
            "  adding 'llama_cpp_python-0.1.78.dist-info/METADATA'\n",
            "  adding 'llama_cpp_python-0.1.78.dist-info/WHEEL'\n",
            "  adding 'llama_cpp_python-0.1.78.dist-info/top_level.txt'\n",
            "  adding 'llama_cpp_python-0.1.78.dist-info/RECORD'\n",
            "  removing _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.78-cp310-cp310-linux_x86_64.whl size=5811071 sha256=ef75e5556e167474774eb7fe58e444ef964f23c0520a6024c21cafcbf1d2f8b3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-snml22t8/wheels/61/f9/20/9ca660a9d3f2a47e44217059409478865948b5c8a1cba70030\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: typing-extensions, numpy, diskcache, llama-cpp-python\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/__pycache__/typing_extensions.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/typing_extensions-4.12.2.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/typing_extensions.py\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Removing file or directory /usr/local/bin/f2py\n",
            "      Removing file or directory /usr/local/bin/f2py3\n",
            "      Removing file or directory /usr/local/bin/f2py3.10\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy-1.25.2.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy.libs/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy/\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  changing mode of /usr/local/bin/f2py to 755\n",
            "  changing mode of /usr/local/bin/f2py3 to 755\n",
            "  changing mode of /usr/local/bin/f2py3.10 to 755\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.0+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.4 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.4 which is incompatible.\n",
            "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed diskcache-5.6.3 llama-cpp-python-0.1.78 numpy-1.23.4 typing-extensions-4.12.2\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.6.2)\n",
            "Requirement already satisfied: llama-cpp-python==0.1.78 in /usr/local/lib/python3.10/dist-packages (0.1.78)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.1.78) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.1.78) (1.23.4)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.1.78) (5.6.3)\n",
            "Requirement already satisfied: numpy==1.23.4 in /usr/local/lib/python3.10/dist-packages (1.23.4)\n"
          ]
        }
      ],
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.78 numpy==1.23.4 --force-reinstall --upgrade --no-cache-dir --verbose\n",
        "!pip install huggingface_hub\n",
        "!pip install llama-cpp-python==0.1.78\n",
        "!pip install numpy==1.23.4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGML\"\n",
        "model_basename = \"llama-2-13b-chat.ggmlv3.q5_1.bin\""
      ],
      "metadata": {
        "id": "N_vy42pqdcVV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qvTgXraAlBHe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)"
      ],
      "metadata": {
        "id": "VI4g2cvtlEmy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "55f6728db4dc46f4bc5c3eb727883cc8",
            "eb623af6f6dd4a66b5cd6827296d434a",
            "bce1bb9d8fa342839ac558ab1a07169b",
            "c46e582fe49c4e41b5c2f41b3813125e",
            "0f5e57bfa5bc4bbbab670312bfd6bf86",
            "da38155496af4e33a3d5c670958da611",
            "ee1c30cd263c4e329477b804bb0939f9",
            "68b6b87cdf7248f8952614fbc7a0d716",
            "7d49b186044a4fc58f36a6b0fab2b9ed",
            "9d4850ada45943a4af77abb4f548baca",
            "3a4f8c8a15ea42d8aab854be156d6eb4"
          ],
          "height": 176
        },
        "outputId": "86b3a79c-1b93-4375-e42d-21fc9985d7b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llama-2-13b-chat.ggmlv3.q5_1.bin:   0%|          | 0.00/9.76G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55f6728db4dc46f4bc5c3eb727883cc8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "lcpp_llm = None\n",
        "lcpp_llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=2, # CPU cores\n",
        "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
        "    n_gpu_layers=32 # Change this value based on your model and your GPU VRAM pool.\n",
        "    )"
      ],
      "metadata": {
        "id": "JBKdKYX4mclG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8227e18f-90b7-44cf-d8db-77bbdceeba40"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lcpp_llm.params.n_gpu_layers"
      ],
      "metadata": {
        "id": "XwOKn14tm6N1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a296b2-6d52-4b8a-e6d3-15681c86fc3d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialisation using LLM"
      ],
      "metadata": {
        "id": "oERE5I7bNyRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "method =' Quasi-Random Sequence'\n",
        "prompt = f\"generate 20 numbers between -10 to 10 by using {method}, only 2 decimal places, \"\n",
        "prompt_template = f'''SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\n",
        "\n",
        "USER: {prompt}\n",
        "\n",
        "ASSISTANT:\n",
        "'''"
      ],
      "metadata": {
        "id": "d1iJ6vDgyyQc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=lcpp_llm(prompt=prompt_template, max_tokens=256, temperature=0.5, top_p=0.95,\n",
        "                  repeat_penalty=1.2, top_k=150,\n",
        "                  echo=True)"
      ],
      "metadata": {
        "id": "kAEc1WZ2nEfB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "-tscz6l65VKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00683bd0-e75d-4f95-e73f-a4ae9f730f46"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-42ad907e-5abd-48d3-9524-003c34adf4e9', 'object': 'text_completion', 'created': 1720720184, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': 'SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\nUSER: generate 20 numbers between -10 to 10 by using  Quasi-Random Sequence, only 2 decimal places, \\n\\nASSISTANT:\\n\\nHere is a list of 20 quasi-random numbers between -10 and 10 with two decimal places:\\n\\n1. -8.47\\n2. -5.93\\n3. -3.69\\n4. -2.25\\n5. -1.08\\n6. 0.87\\n7. 1.78\\n8. 2.69\\n9. 3.59\\n10. 4.47\\n11. 5.38\\n12. 6.27\\n13. 7.15\\n14. 8.02\\n15. 8.90\\n16. 9.77\\n17. 10.64\\n18. 11.50\\n19. 12.35\\n20. 13.20\\n\\nPlease note that these numbers are generated using a Quasi-Random Sequence, which means they may not be perfectly uniform or random, but should still provide a good representation of the range -10 to 10 with two decimal places.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 253, 'total_tokens': 317}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text_response = response['choices'][0]['text']\n",
        "\n",
        "# Use a regular expression to find all numbers in the response\n",
        "numbers = re.findall(r'-?\\d+\\.\\d+', text_response)\n",
        "\n",
        "# Convert the numbers to floats\n",
        "numbers = [float(num) for num in numbers]\n",
        "\n",
        "Quasi_Random_Sequence_Initialisation = numbers\n",
        "print(Quasi_Random_Sequence_Initialisation)"
      ],
      "metadata": {
        "id": "vrYDUpgVnJ75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87f8d24c-b85d-4467-c450-ff02fe600320"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-8.47, -5.93, -3.69, -2.25, -1.08, 0.87, 1.78, 2.69, 3.59, 4.47, 5.38, 6.27, 7.15, 8.02, 8.9, 9.77, 10.64, 11.5, 12.35, 13.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalised Glorot Initialization + Roulette Wheel Selection"
      ],
      "metadata": {
        "id": "9APtR0eO09u4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###PSO Parameters"
      ],
      "metadata": {
        "id": "cCT6psRO09u5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyswarms\n",
        "import numpy as np\n",
        "import pyswarms as ps\n",
        "# from pso.cost_functions import sphere"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e8f5d5-4a88-4d16-fb65-f62ce92020da",
        "id": "5cIzzh-G09u5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyswarms\n",
            "  Downloading pyswarms-1.3.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/104.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyswarms) (1.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyswarms) (1.23.4)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pyswarms) (3.7.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from pyswarms) (23.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pyswarms) (4.66.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyswarms) (0.18.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from pyswarms) (6.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.3.1->pyswarms) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.3.1->pyswarms) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.3.1->pyswarms) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.3.1->pyswarms) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.3.1->pyswarms) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.3.1->pyswarms) (1.16.0)\n",
            "Installing collected packages: pyswarms\n",
            "Successfully installed pyswarms-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initial_position = np.array(numbers)\n",
        "\n",
        "# def objective_function(x):\n",
        "#     return np.sum(x**2)\n",
        "\n",
        "# bounds = (np.array([-10]), np.array([10]))\n",
        "\n",
        "# options = {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
        "\n",
        "# optimizer = ps.single.GlobalBestPSO(n_particles=len(numbers), dimensions=1, options=options, bounds=bounds, init_pos=initial_position.reshape(-1, 1))\n",
        "\n",
        "# best_cost, best_pos = optimizer.optimize(objective_function, iters=100)\n",
        "\n",
        "# print('Best position:', best_pos)\n",
        "# print('Best objective:', best_cost)\n"
      ],
      "metadata": {
        "id": "JG2akeDT09u5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sphere(x):\n",
        "    return sum(x**2)"
      ],
      "metadata": {
        "id": "u60CZwfj09vD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CostFunction = sphere  #\n",
        "nVar = 10  # Number of Decision Variables\n",
        "VarSize = (nVar,)  # Size of Decision Variables Matrix\n",
        "VarMin = -10  # Lower Bound of Variables\n",
        "VarMax = 10  # Upper Bound of Variables"
      ],
      "metadata": {
        "id": "jhHnv4pZ09vD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MaxIt = 20  # Maximum Number of Iterations\n",
        "nPop = np.size(numbers)  # Population Size (Swarm Size)\n",
        "print(nPop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad1a6a9f-5a14-479c-eed3-5ecf88f67eb5",
        "id": "D5ZDvMQ709vD"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = 1  # Inertia Weight\n",
        "wdamp = 0.99  # Inertia Weight Damping Ratio\n",
        "c1 = 1.5  # Personal Learning Coefficient\n",
        "c2 = 2.0  # Global Learning Coefficient"
      ],
      "metadata": {
        "id": "uqQYvuVK09vD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Velocity Limits                        HOWW. ASK BHAIYA ABOUT THIS\n",
        "VelMax = 0.1 * (VarMax - VarMin)\n",
        "VelMin = -VelMax"
      ],
      "metadata": {
        "id": "WKcVIovh09vD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "particles = []\n",
        "\n",
        "for i in range(nPop):\n",
        "    position = np.array([Quasi_Random_Sequence_Initialisation[i]] * nVar)\n",
        "    velocity = np.zeros(VarSize)\n",
        "    cost = CostFunction(position)\n",
        "    best_position = position.copy()\n",
        "    best_cost = cost\n",
        "    particles.append({\n",
        "        'Position': position,\n",
        "        'Velocity': velocity,\n",
        "        'Cost': cost,\n",
        "        'Best': {\n",
        "            'Position': best_position,\n",
        "            'Cost': best_cost\n",
        "        }\n",
        "    })\n",
        "print(np.size(particles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4186d536-a1da-45db-8236-923b29978b3f",
        "id": "qYZhOopW09vD"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GlobalBest = {'Position': None, 'Cost': np.inf}\n",
        "\n",
        "for p in particles:\n",
        "    if p['Cost'] < GlobalBest['Cost']:\n",
        "        GlobalBest = {'Position': p['Best']['Position'].copy(), 'Cost': p['Best']['Cost']}\n",
        "\n",
        "BestCost = np.zeros(MaxIt)"
      ],
      "metadata": {
        "id": "tb35clnx09vD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weight W using LLM"
      ],
      "metadata": {
        "id": "nguFHIlS09vE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w_values = []\n",
        "g_values = []\n",
        "\n",
        "for it in range(MaxIt):\n",
        "    for p in particles:\n",
        "        # Update Velocity\n",
        "        r1 = np.random.rand(*VarSize)\n",
        "        r2 = np.random.rand(*VarSize)\n",
        "        p['Velocity'] = (\n",
        "            w * p['Velocity']\n",
        "            + c1 * r1 * (p['Best']['Position'] - p['Position'])\n",
        "            + c2 * r2 * (GlobalBest['Position'] - p['Position'])\n",
        "        )\n",
        "\n",
        "        # Apply Velocity Limits\n",
        "        p['Velocity'] = np.maximum(p['Velocity'], VelMin)\n",
        "        p['Velocity'] = np.minimum(p['Velocity'], VelMax)\n",
        "\n",
        "        # Update Position\n",
        "        p['Position'] += p['Velocity']\n",
        "\n",
        "        # Velocity Mirror Effect\n",
        "        IsOutside = (p['Position'] < VarMin) | (p['Position'] > VarMax)\n",
        "        p['Velocity'][IsOutside] = -p['Velocity'][IsOutside]\n",
        "\n",
        "        # Apply Position Limits\n",
        "        p['Position'] = np.maximum(p['Position'], VarMin)\n",
        "        p['Position'] = np.minimum(p['Position'], VarMax)\n",
        "\n",
        "        # Evaluation\n",
        "        p['Cost'] = CostFunction(p['Position'])\n",
        "\n",
        "        # Update Personal Best\n",
        "        if p['Cost'] < p['Best']['Cost']:\n",
        "            p['Best']['Position'] = p['Position'].copy()\n",
        "            p['Best']['Cost'] = p['Cost']\n",
        "\n",
        "        print(p['Best']['Cost'])\n",
        "\n",
        "\n",
        "    costs = [p['Best']['Cost'] for p in particles]\n",
        "    costs.append(GlobalBest['Cost'])\n",
        "    min_cost = min(costs)\n",
        "    min_p_best = min([p['Best']['Cost'] for p in particles])\n",
        "\n",
        "    prompt = f\"I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost ({GlobalBest['Cost']}) and various personal best costs from the particles ({min_p_best}). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\"\n",
        "    g_best_finder_template = f'''SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\n",
        "\n",
        "    USER: {prompt}\n",
        "\n",
        "    ASSISTANT:\n",
        "    '''\n",
        "\n",
        "    g_best_response = lcpp_llm(prompt=g_best_finder_template, max_tokens=256, temperature=0.5, top_p=0.95,\n",
        "                              repeat_penalty=1.2, top_k=150,\n",
        "                              echo=True)\n",
        "    print(g_best_response)\n",
        "    g_best_response = g_best_response['choices'][0]['text']\n",
        "    g_best_value = re.findall(r'-?\\d+\\.\\d+', g_best_response)\n",
        "    g_best_value = [float(num) for num in g_best_value]\n",
        "    g_best_value = g_best_value[-1] # take the last value\n",
        "    print(g_best_value)\n",
        "    g_values.append(g_best_value)\n",
        "\n",
        "    if g_best_value < GlobalBest['Cost']:\n",
        "        for p in particles:\n",
        "            if p['Best']['Cost'] == g_best_value:\n",
        "                GlobalBest['Position'] = p['Best']['Position'].copy()\n",
        "                GlobalBest['Cost'] = g_best_value\n",
        "                break\n",
        "\n",
        "    BestCost[it] = GlobalBest['Cost']\n",
        "\n",
        "    print(f\"Iteration {it+1}: Best Cost = {BestCost[it]}\")\n",
        "\n",
        "    prompt = f\"Generate a positive number a little lower than {w} and greater then 0.1 using Normalised Glorot Initialization. Don't write anything else, just write that number in decimal notation normally.\"\n",
        "    w_finder_template = f'''SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\n",
        "\n",
        "    USER: {prompt}\n",
        "\n",
        "    ASSISTANT:\n",
        "    '''\n",
        "\n",
        "    w_response = lcpp_llm(prompt=w_finder_template, max_tokens=256, temperature=0.5, top_p=0.95,\n",
        "                          repeat_penalty=1.2, top_k=150,\n",
        "                          echo=True)\n",
        "\n",
        "    g_values.append(GlobalBest['Cost'])\n",
        "    BestCost[it] = GlobalBest['Cost']\n",
        "\n",
        "    text_response = w_response['choices'][0]['text']\n",
        "    value = re.findall(r'-?\\d+\\.\\d+', text_response)\n",
        "    value = [float(num) for num in value]\n",
        "\n",
        "    value = value[np.size(value) - 1]\n",
        "    print(f'w{it+1} = {value}')\n",
        "    w_values.append(w)\n",
        "    w = value\n",
        "\n",
        "w_values.append(w)\n",
        "print(g_values)\n",
        "print(w_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42fa9f48-db56-4d7d-d87f-7ca8e6646042",
        "id": "hv32tO-G09vE"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "464.3195046257885\n",
            "195.0761829817481\n",
            "36.727443256275095\n",
            "4.916772004478036\n",
            "6.097179312717929\n",
            "7.569\n",
            "18.78750224391873\n",
            "28.813247931201104\n",
            "37.90883605060983\n",
            "75.30752740714465\n",
            "120.42372799806935\n",
            "197.036336533367\n",
            "265.225\n",
            "377.6980094416481\n",
            "482.06137891012736\n",
            "609.6562957440691\n",
            "758.6793640127634\n",
            "910.8396598449469\n",
            "1000.0\n",
            "1000.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-364d0007-dafe-48a1-8fbd-b6b2cf644e59', 'object': 'text_completion', 'created': 1720720315, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (7.569) and various personal best costs from the particles (4.916772004478036). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n     The new minimum global best cost is 4.916772004478036.\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 151, 'completion_tokens': 26, 'total_tokens': 177}}\n",
            "4.916772004478036\n",
            "Iteration 1: Best Cost = 4.916772004478036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w1 = 0.84729356445\n",
            "232.92953226709318\n",
            "60.54950496548552\n",
            "1.5770952689180477\n",
            "4.916772004478036\n",
            "6.097179312717929\n",
            "6.6026722500117145\n",
            "6.650722867064954\n",
            "11.17277208391743\n",
            "2.2520104647792447\n",
            "7.569532626603389\n",
            "24.54968240923823\n",
            "62.641238482282276\n",
            "99.22500000000001\n",
            "174.75621282545558\n",
            "244.38439029172537\n",
            "337.3523792992684\n",
            "450.3656812834676\n",
            "569.1227294811946\n",
            "743.9236183261742\n",
            "658.0614724540495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-fbac641a-2923-4a9d-88ad-c5001183efc8', 'object': 'text_completion', 'created': 1720720369, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (4.916772004478036) and various personal best costs from the particles (1.5770952689180477). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n     The new minimum global best cost is 1.5770952689180477.\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 164, 'completion_tokens': 27, 'total_tokens': 191}}\n",
            "1.5770952689180477\n",
            "Iteration 2: Best Cost = 1.5770952689180477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w2 = 0.77692156387\n",
            "81.5395599083977\n",
            "6.029573318175828\n",
            "1.5770952689180477\n",
            "4.916772004478036\n",
            "5.114216164706113\n",
            "6.6026722500117145\n",
            "6.650722867064954\n",
            "11.17277208391743\n",
            "2.2520104647792447\n",
            "7.569532626603389\n",
            "3.461585793834577\n",
            "5.018719448186597\n",
            "13.22500000000001\n",
            "47.8178104520811\n",
            "86.70740167332342\n",
            "147.31211086417318\n",
            "222.0519985541716\n",
            "307.40579911744226\n",
            "440.7473768880425\n",
            "373.8263574512681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-013733ae-90cc-4ce6-902d-79f310e3047d', 'object': 'text_completion', 'created': 1720720410, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (1.5770952689180477) and various personal best costs from the particles (1.5770952689180477). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n    1.5770952689180477\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 165, 'completion_tokens': 18, 'total_tokens': 183}}\n",
            "1.5770952689180477\n",
            "Iteration 3: Best Cost = 1.5770952689180477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w3 = 0.64782852521\n",
            "10.371533465277915\n",
            "6.029573318175828\n",
            "1.5770952689180477\n",
            "4.916772004478036\n",
            "5.114216164706113\n",
            "5.165804928384782\n",
            "2.1141634092959385\n",
            "3.7510505989040914\n",
            "2.2520104647792447\n",
            "5.69589544820116\n",
            "3.461585793834577\n",
            "5.018719448186597\n",
            "6.896617846052029\n",
            "1.0848159266060926\n",
            "9.941852799102861\n",
            "35.784772247076575\n",
            "73.7383158248756\n",
            "129.8549672992142\n",
            "217.5711354499108\n",
            "174.77593182425625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-27c18365-1e1e-45e8-b70a-2d8d46aeafef', 'object': 'text_completion', 'created': 1720720449, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (1.5770952689180477) and various personal best costs from the particles (1.0848159266060926). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n    1.5770952689180477\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 165, 'completion_tokens': 18, 'total_tokens': 183}}\n",
            "1.5770952689180477\n",
            "Iteration 4: Best Cost = 1.5770952689180477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w4 = 0.59377719745\n",
            "10.23652766627816\n",
            "6.029573318175828\n",
            "1.5770952689180477\n",
            "4.037943385831241\n",
            "2.7386650795196106\n",
            "2.959619448513945\n",
            "2.1141634092959385\n",
            "3.7510505989040914\n",
            "2.2520104647792447\n",
            "5.69589544820116\n",
            "2.754191458936399\n",
            "5.018719448186597\n",
            "6.896617846052029\n",
            "1.0848159266060926\n",
            "7.579979008903867\n",
            "0.768561683626863\n",
            "7.711517160594757\n",
            "27.346481741248073\n",
            "77.6125548466031\n",
            "53.05988509000978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-8f98eae4-e6f3-48b9-bbba-d280e84bc275', 'object': 'text_completion', 'created': 1720720522, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (1.5770952689180477) and various personal best costs from the particles (0.768561683626863). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n    1.5770952689180477\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 164, 'completion_tokens': 18, 'total_tokens': 182}}\n",
            "1.5770952689180477\n",
            "Iteration 5: Best Cost = 1.5770952689180477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w5 = 0.482674587897\n",
            "10.23652766627816\n",
            "6.029573318175828\n",
            "1.5770952689180477\n",
            "4.037943385831241\n",
            "2.7386650795196106\n",
            "1.481844547613812\n",
            "2.1141634092959385\n",
            "3.7510505989040914\n",
            "2.2520104647792447\n",
            "1.511674408634721\n",
            "2.754191458936399\n",
            "5.018719448186597\n",
            "6.896617846052029\n",
            "1.0848159266060926\n",
            "7.579979008903867\n",
            "0.768561683626863\n",
            "7.34851346124462\n",
            "1.7721990601317748\n",
            "12.46693462420458\n",
            "5.495444395800192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-64717937-dcb2-4fbf-83c4-d118540f2515', 'object': 'text_completion', 'created': 1720720558, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (1.5770952689180477) and various personal best costs from the particles (0.768561683626863). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n     The new minimum global best cost is 0.768561683626863.\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 164, 'completion_tokens': 26, 'total_tokens': 190}}\n",
            "0.768561683626863\n",
            "Iteration 6: Best Cost = 0.768561683626863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w6 = 0.395240974575\n",
            "2.9032567229107427\n",
            "6.029573318175828\n",
            "1.5770952689180477\n",
            "3.9834253021852177\n",
            "2.7386650795196106\n",
            "1.210508723410323\n",
            "2.1141634092959385\n",
            "3.7510505989040914\n",
            "2.2520104647792447\n",
            "1.511674408634721\n",
            "2.754191458936399\n",
            "3.135336217500742\n",
            "5.581181264691845\n",
            "1.0848159266060926\n",
            "3.890651745425164\n",
            "0.768561683626863\n",
            "4.113587693319626\n",
            "1.7721990601317748\n",
            "5.017793506737325\n",
            "5.495444395800192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-28a5822d-86eb-4d4f-b37d-21b2f1463d7f', 'object': 'text_completion', 'created': 1720720581, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (0.768561683626863) and various personal best costs from the particles (0.768561683626863). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n    0.768561683626863\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 163, 'completion_tokens': 17, 'total_tokens': 180}}\n",
            "0.768561683626863\n",
            "Iteration 7: Best Cost = 0.768561683626863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w7 = 0.386869484724\n",
            "2.9032567229107427\n",
            "2.6681466456884495\n",
            "1.501611304466739\n",
            "2.1151398108966486\n",
            "2.1918644455357668\n",
            "1.210508723410323\n",
            "0.4032527424338134\n",
            "2.042851506881326\n",
            "1.9596072471217085\n",
            "1.3924484444496765\n",
            "2.754191458936399\n",
            "3.135336217500742\n",
            "5.581181264691845\n",
            "1.0848159266060926\n",
            "3.890651745425164\n",
            "0.768561683626863\n",
            "3.41324021272952\n",
            "1.7721990601317748\n",
            "5.017793506737325\n",
            "5.495444395800192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-6a982d22-9318-42ab-b824-7ac0284f90bd', 'object': 'text_completion', 'created': 1720720601, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (0.768561683626863) and various personal best costs from the particles (0.4032527424338134). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n     The new minimum global best cost is 0.4032527424338134.\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 164, 'completion_tokens': 27, 'total_tokens': 191}}\n",
            "0.4032527424338134\n",
            "Iteration 8: Best Cost = 0.4032527424338134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w8 = 0.352767880865\n",
            "2.0098094778967424\n",
            "2.6681466456884495\n",
            "1.501611304466739\n",
            "1.3458137900486578\n",
            "2.1918644455357668\n",
            "1.210508723410323\n",
            "0.4032527424338134\n",
            "1.3972020913206473\n",
            "1.9596072471217085\n",
            "1.3924484444496765\n",
            "2.754191458936399\n",
            "3.135336217500742\n",
            "2.966882615535085\n",
            "1.0848159266060926\n",
            "2.4889944761077114\n",
            "0.768561683626863\n",
            "3.41324021272952\n",
            "1.7721990601317748\n",
            "4.453111061436633\n",
            "5.495444395800192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-d3e7c822-fee3-430b-8567-1a01eee07640', 'object': 'text_completion', 'created': 1720720622, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (0.4032527424338134) and various personal best costs from the particles (0.4032527424338134). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n    0.4032527424338134\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 165, 'completion_tokens': 18, 'total_tokens': 183}}\n",
            "0.4032527424338134\n",
            "Iteration 9: Best Cost = 0.4032527424338134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w9 = 0.294573209448\n",
            "1.973091371231015\n",
            "2.373451016596276\n",
            "1.501611304466739\n",
            "1.262348786189071\n",
            "1.1460315670818169\n",
            "1.210508723410323\n",
            "0.4032527424338134\n",
            "1.3972020913206473\n",
            "1.1379074451665772\n",
            "0.516810909263875\n",
            "1.4582552959851913\n",
            "2.007706271589689\n",
            "1.4717153736337696\n",
            "0.981716647405121\n",
            "2.4889944761077114\n",
            "0.768561683626863\n",
            "1.4712158498236267\n",
            "1.7721990601317748\n",
            "4.453111061436633\n",
            "5.495444395800192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-14b43df2-3f23-41ec-9ef7-4b3b3c360c37', 'object': 'text_completion', 'created': 1720720642, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (0.4032527424338134) and various personal best costs from the particles (0.4032527424338134). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n    0.4032527424338134\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 165, 'completion_tokens': 18, 'total_tokens': 183}}\n",
            "0.4032527424338134\n",
            "Iteration 10: Best Cost = 0.4032527424338134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w10 = 0.267872974479\n",
            "1.0380623723308335\n",
            "1.5841292958923967\n",
            "1.0535076528006657\n",
            "0.578767249602267\n",
            "0.9650958731631962\n",
            "1.210508723410323\n",
            "0.4032527424338134\n",
            "0.4120285937070757\n",
            "1.1379074451665772\n",
            "0.36097793380645005\n",
            "0.48419704016869813\n",
            "1.0340648090452125\n",
            "1.4717153736337696\n",
            "0.9198573788271649\n",
            "0.481713144609649\n",
            "0.768561683626863\n",
            "0.9098398935053646\n",
            "1.1764633018019437\n",
            "1.8540651673956239\n",
            "2.537810538434641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-55aeca0c-8674-4a40-9984-584edc9de134', 'object': 'text_completion', 'created': 1720720660, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (0.4032527424338134) and various personal best costs from the particles (0.36097793380645005). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n    0.36097793380645005\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 166, 'completion_tokens': 19, 'total_tokens': 185}}\n",
            "0.36097793380645005\n",
            "Iteration 11: Best Cost = 0.36097793380645005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w11 = 0.253125\n",
            "0.8815497289338895\n",
            "1.0357982140760704\n",
            "0.9884478236489757\n",
            "0.4316857491143283\n",
            "0.9619145190996146\n",
            "1.210508723410323\n",
            "0.4032527424338134\n",
            "0.4120285937070757\n",
            "1.1379074451665772\n",
            "0.36097793380645005\n",
            "0.3911049013851577\n",
            "0.6238223589989399\n",
            "1.4717153736337696\n",
            "0.7090107922231599\n",
            "0.481713144609649\n",
            "0.768561683626863\n",
            "0.7102716338652418\n",
            "1.1409842935953634\n",
            "1.7041274663646553\n",
            "2.537810538434641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-50ebce10-f743-434a-95b3-b6ed4ce5e481', 'object': 'text_completion', 'created': 1720720678, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (0.36097793380645005) and various personal best costs from the particles (0.36097793380645005). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n    0.36097793380645005\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 167, 'completion_tokens': 19, 'total_tokens': 186}}\n",
            "0.36097793380645005\n",
            "Iteration 12: Best Cost = 0.36097793380645005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w12 = 0.23456789\n",
            "0.22163620711508406\n",
            "0.8911423925144663\n",
            "0.39514576820107516\n",
            "0.4316857491143283\n",
            "0.39329947882297206\n",
            "1.187252485681044\n",
            "0.4032527424338134\n",
            "0.4120285937070757\n",
            "0.683766565263219\n",
            "0.36097793380645005\n",
            "0.3911049013851577\n",
            "0.29256524434516373\n",
            "0.35978614769391326\n",
            "0.46102248965704623\n",
            "0.481713144609649\n",
            "0.6037162239457831\n",
            "0.5888656553251569\n",
            "1.1000552679273374\n",
            "1.1093309975033976\n",
            "2.537810538434641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-c738ff90-598f-4bbf-a740-94b69460acbd', 'object': 'text_completion', 'created': 1720720704, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (0.36097793380645005) and various personal best costs from the particles (0.22163620711508406). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n    0.22163620711508406\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 167, 'completion_tokens': 19, 'total_tokens': 186}}\n",
            "0.22163620711508406\n",
            "Iteration 13: Best Cost = 0.22163620711508406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w13 = 0.22913255\n",
            "0.18394426978079012\n",
            "0.6053796250279759\n",
            "0.39514576820107516\n",
            "0.425546145888758\n",
            "0.31554541879298503\n",
            "0.4619604406115394\n",
            "0.23188542282392427\n",
            "0.4120285937070757\n",
            "0.2487296273022831\n",
            "0.256957981674553\n",
            "0.3911049013851577\n",
            "0.29256524434516373\n",
            "0.35978614769391326\n",
            "0.28721545426403444\n",
            "0.481713144609649\n",
            "0.5377427702635854\n",
            "0.3791319018380918\n",
            "0.5860703885123563\n",
            "0.3972874892256709\n",
            "1.0426743647754049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-cc8c3694-c869-4afd-9e89-0208fcea3f1a', 'object': 'text_completion', 'created': 1720720738, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (0.22163620711508406) and various personal best costs from the particles (0.18394426978079012). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n    0.18394426978079012\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 167, 'completion_tokens': 19, 'total_tokens': 186}}\n",
            "0.18394426978079012\n",
            "Iteration 14: Best Cost = 0.18394426978079012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w14 = 0.18764329\n",
            "0.18158751532606837\n",
            "0.24432979306462735\n",
            "0.39514576820107516\n",
            "0.19023507560664335\n",
            "0.2104319880223436\n",
            "0.44533374898056194\n",
            "0.18597801131991132\n",
            "0.4120285937070757\n",
            "0.2487296273022831\n",
            "0.21599448447370512\n",
            "0.3911049013851577\n",
            "0.29256524434516373\n",
            "0.1616667416162479\n",
            "0.19989090234553697\n",
            "0.481713144609649\n",
            "0.5132449497572318\n",
            "0.24608315088745747\n",
            "0.24490886147925622\n",
            "0.246407059481845\n",
            "0.8181859253505855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-07546d44-eef7-4570-b59b-e1b03ee6aa8f', 'object': 'text_completion', 'created': 1720720762, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (0.18394426978079012) and various personal best costs from the particles (0.1616667416162479). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n    0.1616667416162479\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 166, 'completion_tokens': 18, 'total_tokens': 184}}\n",
            "0.1616667416162479\n",
            "Iteration 15: Best Cost = 0.1616667416162479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w15 = 0.175\n",
            "0.16052752513816668\n",
            "0.2141843676130194\n",
            "0.33257035102556154\n",
            "0.16882665952966572\n",
            "0.18768040810664258\n",
            "0.08956773576409052\n",
            "0.16823793059566952\n",
            "0.4120285937070757\n",
            "0.2487296273022831\n",
            "0.16090617967296067\n",
            "0.3911049013851577\n",
            "0.20671399423559889\n",
            "0.1616667416162479\n",
            "0.17685188254372436\n",
            "0.481713144609649\n",
            "0.2092010310435321\n",
            "0.1716341382030073\n",
            "0.17250562593277208\n",
            "0.1810695115140307\n",
            "0.6403395368600808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-1bb13eb5-0c17-420b-8bc5-703a478d2e00', 'object': 'text_completion', 'created': 1720720776, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (0.1616667416162479) and various personal best costs from the particles (0.08956773576409052). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n    0.08956773576409052\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 166, 'completion_tokens': 19, 'total_tokens': 185}}\n",
            "0.08956773576409052\n",
            "Iteration 16: Best Cost = 0.08956773576409052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w16 = 0.162\n",
            "0.10058786830214589\n",
            "0.18834724041128464\n",
            "0.296381932010265\n",
            "0.16882665952966572\n",
            "0.11848679656821708\n",
            "0.07760681423103151\n",
            "0.04105754387575525\n",
            "0.3950392429830984\n",
            "0.2487296273022831\n",
            "0.16090617967296067\n",
            "0.09324938263734646\n",
            "0.12365377281931474\n",
            "0.07997318343409138\n",
            "0.11449439307124082\n",
            "0.481713144609649\n",
            "0.12038739859421486\n",
            "0.14865291884246964\n",
            "0.09718785993768278\n",
            "0.1810695115140307\n",
            "0.4287987988462078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-e322a439-2755-4dcb-bfdc-13ac3cfcd5e7', 'object': 'text_completion', 'created': 1720720809, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (0.08956773576409052) and various personal best costs from the particles (0.04105754387575525). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n    0.04105754387575525\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 167, 'completion_tokens': 19, 'total_tokens': 186}}\n",
            "0.04105754387575525\n",
            "Iteration 17: Best Cost = 0.04105754387575525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w17 = 0.145\n",
            "0.05200607822960403\n",
            "0.06864108510356383\n",
            "0.06897397302191978\n",
            "0.16882665952966572\n",
            "0.09929113551284832\n",
            "0.0418097822017559\n",
            "0.04105754387575525\n",
            "0.16579761885924107\n",
            "0.2487296273022831\n",
            "0.1591659079232486\n",
            "0.03086116190053592\n",
            "0.12195866052935052\n",
            "0.04962940986179657\n",
            "0.048113457837759874\n",
            "0.15695252760713416\n",
            "0.0546420086487146\n",
            "0.11601370027451714\n",
            "0.03437703253104902\n",
            "0.06845286222563089\n",
            "0.04354859709135314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-b5c77b1d-e31d-4799-ace7-ab8f8066957a', 'object': 'text_completion', 'created': 1720720824, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (0.04105754387575525) and various personal best costs from the particles (0.03086116190053592). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n     The new minimum global best cost is 0.03086116190053592.\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 167, 'completion_tokens': 28, 'total_tokens': 195}}\n",
            "0.03086116190053592\n",
            "Iteration 18: Best Cost = 0.03086116190053592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w18 = 0.137\n",
            "0.03644653199413592\n",
            "0.05660004877257809\n",
            "0.06897397302191978\n",
            "0.06715604489865354\n",
            "0.04491915014165994\n",
            "0.0418097822017559\n",
            "0.04105754387575525\n",
            "0.09798488382065561\n",
            "0.2487296273022831\n",
            "0.11005045739031297\n",
            "0.03086116190053592\n",
            "0.05557474494042121\n",
            "0.03267537022792057\n",
            "0.048113457837759874\n",
            "0.15695252760713416\n",
            "0.04610221501134283\n",
            "0.05399805119311637\n",
            "0.03437703253104902\n",
            "0.03465674029401574\n",
            "0.04354859709135314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-9eff89ec-0814-4253-b7d7-8af044705944', 'object': 'text_completion', 'created': 1720720861, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (0.03086116190053592) and various personal best costs from the particles (0.03086116190053592). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n    0.03086116190053592\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 167, 'completion_tokens': 19, 'total_tokens': 186}}\n",
            "0.03086116190053592\n",
            "Iteration 19: Best Cost = 0.03086116190053592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w19 = 0.124\n",
            "0.03644653199413592\n",
            "0.047705554083160885\n",
            "0.047385045837921635\n",
            "0.02625335038709811\n",
            "0.036711288872313855\n",
            "0.019832055135802152\n",
            "0.04105754387575525\n",
            "0.058220441451821106\n",
            "0.2447635847251528\n",
            "0.07968972886896407\n",
            "0.027567791833857224\n",
            "0.03718537261119574\n",
            "0.03267537022792057\n",
            "0.048113457837759874\n",
            "0.12993284193586188\n",
            "0.029347493934548406\n",
            "0.031715628290053005\n",
            "0.03437703253104902\n",
            "0.021581477896830115\n",
            "0.03469324967735477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-f97ab488-2d9a-44b9-88ef-2fada61e0edf', 'object': 'text_completion', 'created': 1720720895, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful, respectful, and honest assistant. Always answer as helpfully.\\n\\n    USER: I am using the Particle Swarm Optimization (PSO) algorithm to minimize the cost function. I have multiple cost values from particles in my swarm, including the current global best cost (0.03086116190053592) and various personal best costs from the particles (0.019832055135802152). Using the Roulette_wheel, determine which of these values should be the new minimum global best. Don't write anything else, just write that number in decimal notation normally.\\n\\n    ASSISTANT:\\n    0.019832055135802152\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 168, 'completion_tokens': 20, 'total_tokens': 188}}\n",
            "0.019832055135802152\n",
            "Iteration 20: Best Cost = 0.019832055135802152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w20 = 0.117\n",
            "[4.916772004478036, 4.916772004478036, 1.5770952689180477, 1.5770952689180477, 1.5770952689180477, 1.5770952689180477, 1.5770952689180477, 1.5770952689180477, 1.5770952689180477, 1.5770952689180477, 0.768561683626863, 0.768561683626863, 0.768561683626863, 0.768561683626863, 0.4032527424338134, 0.4032527424338134, 0.4032527424338134, 0.4032527424338134, 0.4032527424338134, 0.4032527424338134, 0.36097793380645005, 0.36097793380645005, 0.36097793380645005, 0.36097793380645005, 0.22163620711508406, 0.22163620711508406, 0.18394426978079012, 0.18394426978079012, 0.1616667416162479, 0.1616667416162479, 0.08956773576409052, 0.08956773576409052, 0.04105754387575525, 0.04105754387575525, 0.03086116190053592, 0.03086116190053592, 0.03086116190053592, 0.03086116190053592, 0.019832055135802152, 0.019832055135802152]\n",
            "[1, 0.84729356445, 0.77692156387, 0.64782852521, 0.59377719745, 0.482674587897, 0.395240974575, 0.386869484724, 0.352767880865, 0.294573209448, 0.267872974479, 0.253125, 0.23456789, 0.22913255, 0.18764329, 0.175, 0.162, 0.145, 0.137, 0.124, 0.117]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(w_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b8a0f0f-913a-4095-968c-fb1be903bc3a",
        "id": "zrRGebV909vE"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0.84729356445, 0.77692156387, 0.64782852521, 0.59377719745, 0.482674587897, 0.395240974575, 0.386869484724, 0.352767880865, 0.294573209448, 0.267872974479, 0.253125, 0.23456789, 0.22913255, 0.18764329, 0.175, 0.162, 0.145, 0.137, 0.124, 0.117]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Roulette_Glorot_weights = w_values\n",
        "plt.plot(Roulette_Glorot_weights)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Normalised Glorot w\")\n",
        "plt.title(\"Values of Normalised Glorot w over Iterations\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "bb5a2551-84e2-4125-dd22-398d08fca660",
        "id": "P7LIdLVi09vE"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Roulette_Glorot_g_values = g_values\n",
        "\n",
        "print(g_values)\n",
        "\n",
        "plt.plot(Roulette_Glorot_g_values)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Ng_values\")\n",
        "plt.title(\"Values of G over Iterations\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "40facc03-0b37-44e2-ee44-8a286633ffa9",
        "id": "gs3QrF7n09vE"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.916772004478036, 4.916772004478036, 1.5770952689180477, 1.5770952689180477, 1.5770952689180477, 1.5770952689180477, 1.5770952689180477, 1.5770952689180477, 1.5770952689180477, 1.5770952689180477, 0.768561683626863, 0.768561683626863, 0.768561683626863, 0.768561683626863, 0.4032527424338134, 0.4032527424338134, 0.4032527424338134, 0.4032527424338134, 0.4032527424338134, 0.4032527424338134, 0.36097793380645005, 0.36097793380645005, 0.36097793380645005, 0.36097793380645005, 0.22163620711508406, 0.22163620711508406, 0.18394426978079012, 0.18394426978079012, 0.1616667416162479, 0.1616667416162479, 0.08956773576409052, 0.08956773576409052, 0.04105754387575525, 0.04105754387575525, 0.03086116190053592, 0.03086116190053592, 0.03086116190053592, 0.03086116190053592, 0.019832055135802152, 0.019832055135802152]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oi3x_1lA09vE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
